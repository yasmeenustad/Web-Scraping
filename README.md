-----> First Scraped the data from the different sites, and cleaned it, and done some visualization.<-----

# Web-Scraping: 
Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications.

## Web scraping can be useful for a variety of purposes, including:
1. Data aggregation: Gathering data from multiple sources for analysis, such as news articles, product prices, or social media posts.
2. Research and monitoring: Collecting data for academic or market research, tracking prices of products or services, or monitoring changes on websites.
3. Content extraction: Extracting specific information from websites, such as contact details, reviews, or job postings.
4. Machine learning training data: Gathering data to train machine learning models, such as collecting images or text from various sources.

## Libraries used for Web Scraping are:
### 1. Requests:
The Requests library is used for sending HTTP requests in Python. It simplifies the process of making GET and POST requests to a web server and receiving responses. It allows you to download the HTML content of web pages.

### 2. BeautifulSoup: 
BeautifulSoup is a Python library for parsing HTML and XML documents. It provides methods to extract data from parsed documents using various techniques, such as searching by tags, attributes, or CSS selectors. BeautifulSoup helps in navigating and manipulating the HTML structure of web pages.

## Data Cleaning:
Data cleaning, also known as data cleansing or data scrubbing, refers to the process of identifying and correcting or removing errors, inconsistencies, and inaccuracies in datasets. It involves transforming raw data into a clean and reliable format suitable for analysis or other data-driven tasks. 

## Data 1:- Amazon Women dresses:
This project is all about the Women's Dresses data, extracted from the Amazon website. The data is extracted by using the BeutifulSoup Python library. The scraped things are Name, Price, Rating, and Link of the particular product. And after scrapping the data, done the data cleaning.

## Data 2:- Swiggy Restaurants Data (Bangalore):
In this extensive project, I successfully scraped a diverse dataset comprising around 1,300 Bangalore restaurant entries, encompassing crucial information like restaurant names, ratings, cuisine types, locations, delivery review numbers, and corresponding URLs. This valuable collection lays the foundation for in-depth analysis and exploration of Bangalore's vibrant culinary landscape.

## Data 3:- Internet Movie Database (IMDb):
Scraped a comprehensive dataset featuring IMDb's top 250 movies. This collection encompasses vital details like movie titles, durations, ratings, IMDb ratings, release years, and convenient links for each entry.





