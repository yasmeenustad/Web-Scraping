-----> First Scraped the data from the different sites, and cleaned it.<-----

# Web-Scrapping: 
Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications.

## Web scraping can be useful for a variety of purposes, including:
1. Data aggregation: Gathering data from multiple sources for analysis, such as news articles, product prices, or social media posts.
2. Research and monitoring: Collecting data for academic or market research, tracking prices of products or services, or monitoring changes on websites.
3. Content extraction: Extracting specific information from websites, such as contact details, reviews, or job postings.
4. Machine learning training data: Gathering data to train machine learning models, such as collecting images or text from various sources.

## Libraries used for Web Scrapping are:
### 1. Requests:
The Requests library is used for sending HTTP requests in Python. It simplifies the process of making GET and POST requests to a web server and receiving responses. It allows you to download the HTML content of web pages.

### 2. BeautifulSoup: 
BeautifulSoup is a Python library for parsing HTML and XML documents. It provides methods to extract data from parsed documents using various techniques, such as searching by tags, attributes, or CSS selectors. BeautifulSoup helps in navigating and manipulating the HTML structure of web pages.

# Data Cleaning:
Data cleaning, also known as data cleansing or data scrubbing, refers to the process of identifying and correcting or removing errors, inconsistencies, and inaccuracies in datasets. 

# Data 1:- Amazon Women dresses:
This project is all about the Women's Dresses data, extracted from the Amazon website. The data is extracted by using the BeutifulSoup Python library.

### Scraped data:



